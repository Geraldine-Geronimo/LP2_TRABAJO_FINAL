{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center\">\n",
    "<strong>WEB SCRAPING - REPOSITORIO DE UNSA</strong>\n",
    "</h1>\n",
    "\n",
    "**Nombre:** Oliverio Pichardo Diestra\n",
    "\n",
    "**Descripción del caso:**\n",
    "Se quiere obtener información estructurada de las tesis de pregrado y posgrado de Estadística \n",
    "Informática o de carreras similares desarrolladas a nivel  nacional, a través de los repositorios \n",
    "institucionales de las universidades.\n",
    "\n",
    "**Especificaciones:**\n",
    "1. Debido a que se menciona carreras similares y no se especifica terminología alguna para ello, \n",
    "entonces se procede a considerar lo establecido por INEI en su *Clasificador Nacional de Programas e Instituciones de \n",
    "Educación Superior Universitaria, Pedagógica, Tecnológica y Técnico Productiva, 2018*. (Ver Tabla 1)\n",
    "\n",
    "    **Tabla 1**  \n",
    "    *Programas similares a Estadística a nivel de profesional (pregrado)*\n",
    "    | CÓDIGO |                      PROGRAMA                     |\n",
    "    |:------:|:-------------------------------------------------:|\n",
    "    | 542016 |                    Estadística                    |\n",
    "    | 542026 |             Estadística e informática             |\n",
    "    | 542036 |              Estadística informática              |\n",
    "    | 542046 | Estadística para la gestión de servicios de salud |\n",
    "    | 542056 |               Ingeniería estadística              |\n",
    "    | 542066 |        Ingeniería estadística e informática       |\n",
    "    | 542076 |         Ingeniería estadística informática        |\n",
    "    | 542996 |           Otros programas en estadística          |\n",
    "\n",
    "    *Nota: Adaptado de \"Clasificador Nacional de Programas e Instituciones de \n",
    "    Educación Superior Universitaria, Pedagógica, Tecnológica y Técnico Productiva, 2018\" por INEI.*\n",
    "\n",
    "2. El repositorio escogido es el de la Universidad Nacional de San Agustín de Arequipa (UNSA). \n",
    "El respectivo url de dicho repositorio es:  http://repositorio.unsa.edu.pe/browse?type=dateissued **(url-principal)**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Web Scraping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Librerías, módulos o paquetes\n",
    "A fin de realizar la extracción de datos pertinentes, se emplearán las siguientes librerías, módulos o paquetes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando librerías, módulos o paquetes pertinentes\n",
    "# %pip install requests\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import itertools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Funciones\n",
    "Se definirán dos funciones las cuales tendrán los siguientes objetivos respectivamente:\n",
    "1. Extraer todas las urls de la diversas páginas de la *url-principal* en las que se encuentran las tesis de pregrado y posgrado. Tales urls serán denominadas *url-página*.\n",
    "2. De cada *url-página*, extraer las urls que contienen la información específica de cada una las tesis. A estas les denominaremos *url-publicación*.\n",
    "\n",
    "A fin de comprender mejor lo mencionado, veamos la estructura jerárquica:\n",
    "1. Nivel 1 (url-principal): http://repositorio.unsa.edu.pe/browse?type=dateissued\n",
    "2. Nivel 2 (url-página): Es una subpágina de la url-principal que contiene en promedio 20 publicaciones. Hasta la fecha, en total, existen 682 subpáginas.\n",
    "3. Nivel 3 (url-publicación): Es una subpágina de una url-página que contiene la información específica de una determinada publicación. Hasta el momento, contiene en promedio 28 descriptores de la respectiva publicación."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. Extracción de todas las url-página de la url-principal\n",
    "A fin de realizar la extracción de todas las url-página de la url-principal, se identificó un patrón de url que sirve para generar todas las url-página. A esa se le denominará *url-base*.\n",
    "A continuación, se define una función en la que:\n",
    "1. se identifica la url-base,\n",
    "2. se crea una lista de los caracteres que se deben reemplazar en el url-base para generar todas la url-página y\n",
    "3. se generan las url-página mediante la sustitución de unos caracteres específicos de la url-base por los elementos la lista generada en el punto 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando una función que permite extraer todas las url-página\n",
    "def all_pages(url):\n",
    "    # Descargar el contenido de la url-principal\n",
    "    page = requests.get(url)\n",
    "    # Crear un objeto BeautifulSoup a partir del contenido de la página\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    # Encontrar el tag a que contiene la url-base de las url-página\n",
    "    pages = soup.find_all(\"a\", {\"class\":\"next-page-link\"})\n",
    "    # Extraer el url-base de las url-página\n",
    "    pages_soup = BeautifulSoup(str(pages), 'html.parser')\n",
    "    a_tags = pages_soup.find_all('a') # find all anchor elements\n",
    "    base_href = [\"http://repositorio.unsa.edu.pe/\" + a_tag['href'] for a_tag in a_tags][0]\n",
    "    # Crear lista de límites inferiores de cada url-página\n",
    "    string_pages = soup.find_all(\"p\", {\"class\":\"pagination-info\"})\n",
    "    matches = re.findall(\"\\d+\", str(string_pages[0]))\n",
    "    lower_limit_max = (max([int(item) for item in matches]) // 20) * 20\n",
    "    lower_limits = list(range(0, lower_limit_max + 20, 20))\n",
    "    # Crear lista de las url-página de la url-principal\n",
    "    hrefs_all = [re.sub(r\"offset=\\d+\", \"offset=\" + str(pag), base_href) for pag in lower_limits]\n",
    "    return hrefs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5df2bbc9074bc7b86f029b01b4b6c677caf98f9d22ebc6f989a43f921d559b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
